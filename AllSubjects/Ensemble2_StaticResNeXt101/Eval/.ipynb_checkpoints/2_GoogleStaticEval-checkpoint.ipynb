{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from torchvision import datasets, models, transforms\n",
    "from imgaug import augmenters as iaa\n",
    "from sklearn.externals import joblib\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import imgaug as ia\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import pickle\n",
    "import joblib\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python3.7/site-packages/imgaug/imgaug.py:182: DeprecationWarning: Function `Scale()` is deprecated. Use `Resize` instead. Resize has the exactly same interface as Scale.\n",
      "  warn_deprecated(msg, stacklevel=3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0881, 1.6036]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.5022, -0.2157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1542, -0.8852]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.6195,  4.2671]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2646, 1.2385]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7558, 0.7941]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0688,  1.4722]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5056,  1.4102]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.1238,  3.5921]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7480, -0.6171]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.9815,  3.9353]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4221,  2.7896]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8572,  2.3309]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 3.0234, -1.1528]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0839,  3.9767]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.7926, -0.5760]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0330,  3.0932]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2398, 0.4694]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.4427, -0.0935]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.3801,  2.5397]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1714,  2.3938]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.0938, -1.3815]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5897,  2.2561]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.3402, -0.3699]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.2175,  2.3349]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.9747, -0.5991]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5479,  2.3404]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.9717, -0.8082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5126, 0.0016]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.7333,  3.2892]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.1781, -1.1849]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.1263, 0.3049]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.3940, 0.7261]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3310, 2.0763]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.5128, -1.6489]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.0333, -0.4836]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5187,  5.3454]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3538, 0.5713]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4835,  2.0039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.8641,  2.5889]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.0383,  4.3098]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.4445, 0.4913]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.6625,  3.6046]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2108, 0.9039]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0692,  1.5648]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6812,  2.4133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 3.0339, -0.7238]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.9495, 0.1490]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.1221,  3.6435]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2207, 0.7754]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2991, -0.0436]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.9109, 0.2729]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7055, 0.7715]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 3.8132, -2.9236]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.3942,  1.4032]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7719,  3.1189]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.1887,  2.4157]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.5470,  1.7616]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.0176,  3.4133]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.6858, -0.3250]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.7690, -0.9625]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2260, -0.8773]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5211, 1.2777]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.5352,  4.7431]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.7517,  2.7292]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.6201, 0.4619]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.4377, -0.5863]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.6914, -1.5688]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.1973,  4.6412]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.1770,  1.9483]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.6584, -0.1934]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.7349,  3.7342]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.2800, -0.2521]], grad_fn=<AddmmBackward>)\n",
      "tensor([[2.3478, 0.0203]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.0258, -0.8300]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.0346,  2.5514]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.3615,  1.4383]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.4296, 0.1011]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0199, 0.3560]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4091,  1.5186]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.6336,  2.3881]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.5727, 0.7434]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-3.5446,  6.5433]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0883,  2.3744]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.2567,  3.4072]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-2.7642,  4.2334]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-0.4355,  2.0789]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.6191, -0.2875]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.3943, 0.8149]], grad_fn=<AddmmBackward>)\n",
      "tensor([[1.0018, 1.0885]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 0.8783, -0.4690]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.9022, -0.5750]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 3.2879, -1.8020]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.3812, 1.2267]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.2830, 1.3834]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 2.0715, -1.1517]], grad_fn=<AddmmBackward>)\n",
      "tensor([[ 1.3765, -1.0361]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.2392,  2.6808]], grad_fn=<AddmmBackward>)\n",
      "tensor([[0.7957, 1.1082]], grad_fn=<AddmmBackward>)\n",
      "tensor([[-1.0271,  3.3287]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "class ImgAugTransform:\n",
    "  def __init__(self):\n",
    "    self.aug = iaa.Sequential([\n",
    "        iaa.Scale((224, 224)),\n",
    "        iaa.Sometimes(0.25, iaa.GaussianBlur(sigma=(0, 3.0))),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Affine(rotate=(-20, 20), mode='symmetric'),\n",
    "        iaa.Sometimes(0.25,\n",
    "                      iaa.OneOf([iaa.Dropout(p=(0, 0.1)),\n",
    "                                 iaa.CoarseDropout(0.1, size_percent=0.5)])),\n",
    "        iaa.AddToHueAndSaturation(value=(-10, 10), per_channel=True)\n",
    "    ])\n",
    "      \n",
    "  def __call__(self, img):\n",
    "    img = np.array(img)\n",
    "    return self.aug.augment_image(img)\n",
    "\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        ImgAugTransform(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "model_ft = joblib.load(\"../GoogleStatic_ResNet18.sav\")\n",
    "\n",
    "data = pd.read_csv(\"./y1314_df.csv\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "cfail = []\n",
    "cpass = []\n",
    "ids = []\n",
    "label = []\n",
    "\n",
    "directory = \"./jpg/\"\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    school_id = filename[0:6]\n",
    "    ids.append(school_id)\n",
    "    info = data[data['school_id'] == int(school_id)]\n",
    "    label.append(info.intervention.tolist()[0])\n",
    "    img = Image.open(directory + filename)\n",
    "    cnn_input = data_transforms(img).unsqueeze(0)\n",
    "    model_ft.eval()\n",
    "    pred = model_ft(cnn_input)\n",
    "    print(pred) \n",
    "    preds = pred.softmax(1).tolist()\n",
    "    cfail.append(preds[0][0])\n",
    "    cpass.append(preds[0][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  school_id  label      pass      fail  pred  correct\n",
      "0    300897      0  0.819868  0.180132     0        1\n",
      "1    107371      0  0.152147  0.847853     1        0\n",
      "2    305290      1  0.115126  0.884874     1        1\n",
      "3    105374      0  0.997232  0.002768     0        1\n",
      "4    106480      0  0.725892  0.274108     0        1\n",
      "1    80\n",
      "0    20\n",
      "Name: correct, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Make the data frame withthe soft probabilities, predicted class labels and actual labels\n",
    "df['school_id'] = ids\n",
    "df['label'] = label\n",
    "df['pass'] = cpass\n",
    "df['fail'] = cfail\n",
    "df['pred'] = 99\n",
    "df['correct'] = 0\n",
    "\n",
    "df['pred'][df['pass'] >= .50] = 0\n",
    "df['pred'][df['pass'] < .50] = 1\n",
    "\n",
    "df[\"correct\"][(df['label'] == 0) & (df[\"pred\"] == 0)] = 1\n",
    "df[\"correct\"][(df['label'] == 1) & (df[\"pred\"] == 1)] = 1\n",
    "\n",
    "print(df.head())\n",
    "print(df['correct'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "80 / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./GoogleStaticPreds.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
